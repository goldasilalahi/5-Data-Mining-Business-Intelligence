{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"f48418587c6343c7845ec7fcb8ba1bd0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5112dd3b41db4b529709490e4bfeecaf","IPY_MODEL_7c7d44370e4d456e937b2506272253dc","IPY_MODEL_0cac3f7978a84474b0fb8f3b90a0f0e9"],"layout":"IPY_MODEL_18b0858f18d84c32ac2a7b246c876301"}},"5112dd3b41db4b529709490e4bfeecaf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49dfaafc1fca4a8ba8bf83bfb7f7f9b5","placeholder":"​","style":"IPY_MODEL_c62685b6ebb44a829b3fd415c1bce546","value":"tokenizer_config.json: 100%"}},"7c7d44370e4d456e937b2506272253dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c7dd40ad4f54488950739fd0b2607a9","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43546f85191f47d5abdc0348b64fbca0","value":25}},"0cac3f7978a84474b0fb8f3b90a0f0e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be4b332be46e4ffbadc0f4235b3fd4c9","placeholder":"​","style":"IPY_MODEL_c906392c5214427ca9921190afe4166e","value":" 25.0/25.0 [00:00&lt;00:00, 1.03kB/s]"}},"18b0858f18d84c32ac2a7b246c876301":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49dfaafc1fca4a8ba8bf83bfb7f7f9b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c62685b6ebb44a829b3fd415c1bce546":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c7dd40ad4f54488950739fd0b2607a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43546f85191f47d5abdc0348b64fbca0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be4b332be46e4ffbadc0f4235b3fd4c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c906392c5214427ca9921190afe4166e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5333aff53d24763a0dc3386bf9b23da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f68e323430a243c5a2d37fb2a9d6e85a","IPY_MODEL_9d413eae1c86447eb74993b55c06dfc9","IPY_MODEL_f71585dfae48455ea40b0aa96bbeed60"],"layout":"IPY_MODEL_1546c7f80f9b48f58f11549345a7a6b4"}},"f68e323430a243c5a2d37fb2a9d6e85a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fefc6c1f6854220877bb14f0a1ab980","placeholder":"​","style":"IPY_MODEL_a5ac97921a8a4d01b8b438ff7ec697e9","value":"vocab.json: 100%"}},"9d413eae1c86447eb74993b55c06dfc9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_de41f10916db441f80a163f1f89a266b","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2efc93f9074f41b1acd0fce1f5e33bc5","value":898823}},"f71585dfae48455ea40b0aa96bbeed60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd3e1372cbaf49f6b9cf3ddff4712dd9","placeholder":"​","style":"IPY_MODEL_1e08b879881c4f67ae249f452f942950","value":" 899k/899k [00:00&lt;00:00, 4.12MB/s]"}},"1546c7f80f9b48f58f11549345a7a6b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fefc6c1f6854220877bb14f0a1ab980":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5ac97921a8a4d01b8b438ff7ec697e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de41f10916db441f80a163f1f89a266b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2efc93f9074f41b1acd0fce1f5e33bc5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd3e1372cbaf49f6b9cf3ddff4712dd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e08b879881c4f67ae249f452f942950":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1ef8e9a1eec4fccb555abb65edf3443":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bfc7b12de76b4c41a5dfbb4fd8272298","IPY_MODEL_89fcb5d9cca74078b0e2925d95489d7e","IPY_MODEL_731f24d9dd8542a8bed6a7545609f9d7"],"layout":"IPY_MODEL_bb705fe0fc0c4c91825f8094e9eddf65"}},"bfc7b12de76b4c41a5dfbb4fd8272298":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f27c8f1112c84cb5b6debe3a68efbadd","placeholder":"​","style":"IPY_MODEL_9ad470cad01849c1a48b20ed78c3752f","value":"merges.txt: 100%"}},"89fcb5d9cca74078b0e2925d95489d7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1907beb85da14d2b9f48b18e1efb57c1","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f409a708c1749d096a5e51c88859b46","value":456318}},"731f24d9dd8542a8bed6a7545609f9d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4f11c2497a9494a8bc088e2851dfc38","placeholder":"​","style":"IPY_MODEL_ea89bed227aa4b6db5eacd5e2d20bba4","value":" 456k/456k [00:00&lt;00:00, 1.05MB/s]"}},"bb705fe0fc0c4c91825f8094e9eddf65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f27c8f1112c84cb5b6debe3a68efbadd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ad470cad01849c1a48b20ed78c3752f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1907beb85da14d2b9f48b18e1efb57c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f409a708c1749d096a5e51c88859b46":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4f11c2497a9494a8bc088e2851dfc38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea89bed227aa4b6db5eacd5e2d20bba4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43efce16381f4a738c8364fe0e34481c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_330d01a4adf74284bd826176995153ec","IPY_MODEL_b21c494f83f747a89e9947d514ff82ea","IPY_MODEL_befcd93ff26f4e25a27f98ac1c6ad1ad"],"layout":"IPY_MODEL_f12333f5d9c64429b9f59183f814842f"}},"330d01a4adf74284bd826176995153ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bd8d8dfab6042499b30ba84e0de3fa8","placeholder":"​","style":"IPY_MODEL_4f76871a42ee4a229e31e7867a1c7447","value":"tokenizer.json: 100%"}},"b21c494f83f747a89e9947d514ff82ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bb123b1cd084366b41e4e3dd041d09e","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6231698f3174ef4a4a1743db1021a49","value":1355863}},"befcd93ff26f4e25a27f98ac1c6ad1ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17518d71e3f84227bc75caa25e0ac9cf","placeholder":"​","style":"IPY_MODEL_df6dfbe8cd604a41a8faa53f72181793","value":" 1.36M/1.36M [00:00&lt;00:00, 1.57MB/s]"}},"f12333f5d9c64429b9f59183f814842f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bd8d8dfab6042499b30ba84e0de3fa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f76871a42ee4a229e31e7867a1c7447":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bb123b1cd084366b41e4e3dd041d09e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6231698f3174ef4a4a1743db1021a49":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"17518d71e3f84227bc75caa25e0ac9cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df6dfbe8cd604a41a8faa53f72181793":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb5e79d9bc134a79ae050733b68c7394":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_87f6928507264437b5ad56e32763983d","IPY_MODEL_f09d29a7b5b84c45a4493aa46c419cbf","IPY_MODEL_9d65d13a864446f29f502a2c70c93c23"],"layout":"IPY_MODEL_d9173e083ec344fcaade5c869fe981db"}},"87f6928507264437b5ad56e32763983d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a5ad5b4f5254423ab8ff524fd29e5ed","placeholder":"​","style":"IPY_MODEL_3d62294085e342ec906cc14e1d56c933","value":"config.json: 100%"}},"f09d29a7b5b84c45a4493aa46c419cbf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dad9860e44f9451ca4fb5bea3c3b9779","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_964d282cf1d440b0adb34531d6d68690","value":481}},"9d65d13a864446f29f502a2c70c93c23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54cc4f53519e42f586fe6185390d9609","placeholder":"​","style":"IPY_MODEL_a8eb2743f88a47c09a417912b80d625b","value":" 481/481 [00:00&lt;00:00, 25.7kB/s]"}},"d9173e083ec344fcaade5c869fe981db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a5ad5b4f5254423ab8ff524fd29e5ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d62294085e342ec906cc14e1d56c933":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dad9860e44f9451ca4fb5bea3c3b9779":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"964d282cf1d440b0adb34531d6d68690":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54cc4f53519e42f586fe6185390d9609":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8eb2743f88a47c09a417912b80d625b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7aa4b8b8309745e48dc2060cfc96f71e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d55ec8972f3745b7bc4d24ada270a87f","IPY_MODEL_71bb19ec279e4912ada5a28cf376b006","IPY_MODEL_79d98b7dd2d244bdb9fba859c218986e"],"layout":"IPY_MODEL_b49975f9d7ef497c99bcaa2cee0e35ed"}},"d55ec8972f3745b7bc4d24ada270a87f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bca966bdea5408e8d2373c155bcc12c","placeholder":"​","style":"IPY_MODEL_80c39d9d8444441196219bcec814ccd8","value":"model.safetensors: 100%"}},"71bb19ec279e4912ada5a28cf376b006":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_85fa5df1a02d4ae3a913721520886d39","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f1de601040d43bf972dfdb5ce878652","value":498818054}},"79d98b7dd2d244bdb9fba859c218986e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a74c0d6428b4c8784294ab20ef2cb30","placeholder":"​","style":"IPY_MODEL_ff33c55e14b24d6f9f7774ca140450e2","value":" 499M/499M [00:02&lt;00:00, 240MB/s]"}},"b49975f9d7ef497c99bcaa2cee0e35ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bca966bdea5408e8d2373c155bcc12c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80c39d9d8444441196219bcec814ccd8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85fa5df1a02d4ae3a913721520886d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f1de601040d43bf972dfdb5ce878652":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a74c0d6428b4c8784294ab20ef2cb30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff33c55e14b24d6f9f7774ca140450e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Studi Kasus Data Mining: Text Mining**\n\n### **Tabel Kontribusi Kelompok 7:**\n\n| Nama                                | NPM        | Kontribusi                                          | % Kontribusi |\n|-------------------------------------|------------|-----------------------------------------------------|--------------|\n| Golda Aurelia Silalahi              | 2206826173 | Terlibat aktif dalam diskusi dan ikut serta dalam mengerjakan keseluruhan bagian. | 100%         |\n| Yiesha Reyhani                      | 2206828115 | Terlibat aktif dalam diskusi dan ikut serta dalam mengerjakan keseluruhan bagian. | 100%         |\n| Jason Justin Andryana               | 2206029670 | Terlibat aktif dalam diskusi dan ikut serta dalam mengerjakan keseluruhan bagian. | 100%         |\n| Aditya Raja Fadlurahman Kusuma      | 2206051626 | Terlibat aktif dalam diskusi dan ikut serta dalam mengerjakan keseluruhan bagian. | 100%         |\n\n<br>\n\n\n### **Natural Language Processing with Disaster Tweets**\n\n**Sumber Data**: [Kaggle - Natural Language Processing with Disaster Tweets](https://www.kaggle.com/competitions/nlp-getting-started/data)\n\nDataset ini berisi 10,000 tweet yang telah diklasifikasikan secara manual untuk memprediksi apakah sebuah tweet terkait dengan bencana nyata atau tidak. Dataset ini dapat digunakan untuk melatih model machine learning yang dapat membedakan antara tweet tentang bencana nyata dan tweet yang tidak relevan. Berikut adalah deskripsi dari masing-masing kolom dalam dataset:\n\n| Variable Name  | Description                                                                                              |\n|----------------|----------------------------------------------------------------------------------------------------------|\n| id             | Identifikasi unik untuk setiap tweet                                                                     |\n| text           | Teks dari tweet                                                                                          |\n| location       | Lokasi dari mana tweet dikirim (dapat kosong)                                                            |\n| keyword        | Kata kunci tertentu dari tweet (dapat kosong)                                                            |\n| target         | Hanya ada di *train.csv*, menunjukkan apakah tweet terkait dengan bencana nyata (1) atau tidak (0)       |\n\n <br>\n\n","metadata":{"id":"pIra4c8oq-BX"}},{"cell_type":"markdown","source":"## **Import Libraries and Load Data**","metadata":{"id":"g0ZMtuDFsl-A"}},{"cell_type":"code","source":"# Import Library\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import f1_score\n\nimport spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom scipy.sparse import hstack\n!pip install contractions\nimport contractions\nimport warnings\nfrom wordcloud import STOPWORDS, WordCloud\nfrom collections import Counter\n\nimport nltk\nnltk.download('wordnet')\nnltk.download('punkt_tab')\nnltk.download('stopwords')\nfrom nltk.stem import WordNetLemmatizer, SnowballStemmer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\n# Import dari scikit-learn (sklearn)\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n# Set seed\nSEED = 825\n\n# Warnings and display settings\nwarnings.filterwarnings('ignore')","metadata":{"id":"0b-FPSWWqJgW","collapsed":true,"outputId":"3105d8cf-50b7-403e-927c-0ee3bba722dd","jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Data\nurl = 'https://raw.githubusercontent.com/goldasilalahi/data-mining-and-business-intelligence/refs/heads/main/'\n\ntrain_df = pd.read_csv(url + 'train3.csv', delimiter=',') # train\ntest_df = pd.read_csv(url + 'test3.csv', delimiter=',') # test\nss_df = pd.read_csv(url + 'sample_submission3.csv', delimiter=',') # submission","metadata":{"id":"S_9p8Fd1pqIK"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cuplikan data train\ntrain_df.head()","metadata":{"id":"-TQsmrKvrMGw","outputId":"c1c15ea1-885c-45f8-f49d-9b9f2c60a121"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## EDA","metadata":{"id":"HXninyNJIiMP"}},{"cell_type":"code","source":"# Cek data shape\nprint(\"Train Dataset Shape:\", train_df.shape)\nprint(\"Test Dataset Shape:\", test_df.shape)\nprint(\"Submission Dataset Shape:\", ss_df.shape)","metadata":{"id":"9xylxFpDg1p0","outputId":"1985e705-5f1e-421a-f1d0-ce6e7ac6640a"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Akan dicek missing value pada data train dan data test.","metadata":{"id":"qGAykjrvQE_A"}},{"cell_type":"code","source":"# Cek missing values\ntrain_df.isnull().sum().rename(\"Missing Value Amount(Train data)\")","metadata":{"id":"IYGZBaonwlwW","outputId":"20f88fa0-48d9-4740-9696-869b6af8b166"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"(train_df.isnull().sum()/train_df.shape[0]*100).rename(\"Missing values percentage per kolom (Train data)\")","metadata":{"id":"NtO0kcCqxL5_","outputId":"013c8128-f3ca-463e-fba1-871bfc3b9bf7"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.isnull().sum().rename(\"Missing values percentage per kolom (Test data)\")","metadata":{"id":"SS8NpnpMw5_C","outputId":"225ac24e-43d8-4b5c-bbea-570370ab33f1"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"(test_df.isnull().sum()/test_df.shape[0]*100).rename(\"Missing values percentage per kolom (Test data)\")","metadata":{"id":"f7_wnNfGyg2q","outputId":"d657ce47-3e9b-4c40-a877-9d8ddb25bf64"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Terdapat missing value pada fitur keyword dan location, dengan paling banyak pada location. Kita tidak akan menggunakan fitur tersebut untuk membuat model, sehingga akan dibiarkan.","metadata":{"id":"kGhxzAoNyvRI"}},{"cell_type":"code","source":"# Cek duplikasi\nduplicate_rows_train = train_df[train_df.duplicated()]\nprint(f\"Number of duplicate rows in train_df: {len(duplicate_rows_train)}\")","metadata":{"id":"_-W1KHRNj1Kx","outputId":"1d05c642-81c2-4659-d530-6f262cdb15db"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Tidak terdapat data duplikat, namun akan kita cek apakah terdapat fitur text yang duplikat.\n","metadata":{"id":"6TUoL-xP0Vkt"}},{"cell_type":"code","source":"# Cek duplikasi di data train\nprint(\"\\nJumlah duplikasi data pada kolom Text di Train Data:\")\nprint(train_df[\"text\"].duplicated().sum())\n# Cek duplikasi di data test\nprint(\"\\nJumlah duplikasi data pada kolom Text di Test Data:\")\nprint(test_df[\"text\"].duplicated().sum())","metadata":{"id":"Vb-xbmzlxVD0","outputId":"b8abbdab-6d4c-4c08-ce02-9c0bedb81716"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Tidak terdapat data duplikat, namun akan kita cek apakah terdapat fitur text yang duplikat.\n","metadata":{"id":"0rL9uK5ymXxr"}},{"cell_type":"code","source":"# Cek duplikasi text di data train\nduplicates = pd.concat(x for _, x in train_df.groupby([\"text\"]) if len(x) > 1)\nwith pd.option_context(\"display.max_rows\", None, \"max_colwidth\", 240):\n    display(duplicates[[\"id\", \"target\", \"text\"]])","metadata":{"outputId":"13cbc780-a2d8-431b-b186-5cc143dec34e","id":"Fn1PAg2oLfsU"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Terlihat bahwa ada duplikasi pada text dari data train. Beberapa memiliki kelas target yang sama, namun ada juga yang memiliki kelas target berbeda. Untuk tweet dengan kelas yang sama, akan dihapus duplikatnya.","metadata":{"id":"v48ssrdxLnHK"}},{"cell_type":"code","source":"# Drop duplikat\ntrain_df.drop(\n    [\n        6449, 7034, 3589, 3591, 3597, 3600, 3603,\n        3604, 3610, 3613, 3614, 119, 106, 115,\n        2666, 2679, 1356, 7609, 3382, 1335, 2655,\n        2674, 1343, 4291, 4303, 1345, 48, 3374,\n        7600, 164, 5292, 2352, 4308, 4306, 4310,\n        1332, 1156, 7610, 2441, 2449, 2454, 2477,\n        2452, 2456, 3390, 7611, 6656, 1360, 5771,\n        4351, 5073, 4601, 5665, 7135, 5720, 5723,\n        5734, 1623, 7533, 7537, 7026, 4834, 4631,\n        3461, 6366, 6373, 6377, 6378, 6392, 2828,\n        2841, 1725, 3795, 1251, 7607\n    ], inplace=True\n)\nduplicates = pd.concat(x for _, x in train_df.groupby([\"text\"]) if len(x) > 1)\nwith pd.option_context(\"display.max_rows\", None, \"max_colwidth\", 240):\n    display(duplicates[[\"id\", \"target\", \"text\"]])","metadata":{"outputId":"c8125b52-5e9f-40cf-ca70-d48b68b4a40f","id":"luVRu_U6MykJ"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Kita tidak tahu metode yang digunakan oleh pembuat dataset untuk melabel kelas target. Sehingga, cukup sulit untuk memutuskan mana kelas target yang benar untuk data duplikasi dengan kelas target berbeda. Sehingga, kami memutuskan untuk menghapus data duplikasi yang bermasalah. Meskipun akan mengurangi ukuran data. lebih baik untuk memastikan tidak ada bias yang tidak disengaja.","metadata":{"id":"KrM6sy8YM0C-"}},{"cell_type":"code","source":"# Drop duplikat\ntrain_df.drop(\n    [\n        4290, 4299, 4312, 4221, 4239, 4244, 2830,\n        2831, 2832, 2833, 4597, 4605, 4618, 4232,\n        4235, 3240, 3243, 3248, 3251, 3261, 3266,\n        4285, 4305, 4313, 1214, 1365, 6614, 6616,\n        1197, 1331, 4379, 4381, 4284, 4286, 4292,\n        4304, 4309, 4318, 610, 624, 630, 634, 3985,\n        4013, 4019, 1221, 1349, 6091, 6094,\n        6103, 6123, 5620, 5641\n    ], inplace=True\n)","metadata":{"id":"hQdd0OAVNNQA"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train Dataset Shape:\", train_df.shape)","metadata":{"outputId":"8b676407-860d-4b8e-a8ff-a37f3bc960c8","id":"9qbLbluVmXxs"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df","metadata":{"id":"u3r-P_ckaLMw","outputId":"03158ecf-8d2d-429d-f360-87c483cf4435"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train Dataset Shape:\", train_df.shape)","metadata":{"id":"EH7ROC1oQQys","outputId":"b8eee6b0-4008-42bb-b955-3af42825df76"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Distribusi target\nplt.figure(figsize=(12, 6))\n\n# Pie Chart\nplt.subplot(1, 2, 1)\ntarget_counts = train_df['target'].value_counts()\nplt.pie(target_counts, labels=['Not Disaster', 'Disaster'], autopct='%1.1f%%', startangle=90, colors=sns.color_palette('Dark2'))\nplt.title('Distribution of Target Variable')\nplt.legend(['Not Disaster', 'Disaster'], loc='upper right')  # Add legend\n\n# Bar Chart\nplt.subplot(1, 2, 2)\nax = sns.countplot(x='target', data=train_df, palette='Dark2')\nplt.title('Distribution of Target Variable')\nplt.xlabel('Target')\nplt.ylabel('Count')\n\n# Annotate bar chart\nfor p in ax.patches:\n    ax.annotate(f'{int(p.get_height())}',\n                (p.get_x() + p.get_width() / 2., p.get_height()),\n                ha='center', va='bottom')\n\n# Update xtick labels\nax.set_xticklabels(['Not Disaster', 'Disaster'])  # Set labels for x ticks\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"C9CYLCsnQd-b","outputId":"fa36ccb7-4274-44ef-f3ad-b6a913149a0f"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Berdasarkan grafik distribusi kelas target, terlihat bahwa distribusinya cukup seimbang (tidak imbalance).","metadata":{"id":"2KT7oqeAORG6"}},{"cell_type":"code","source":"# Plot distribusi panjang text berdasar target\ndef plot_text_length_distribution(df, text_column='text', target_column='target'):\n    # Drop rows with missing values in the text or target columns\n    df = df.dropna(subset=[text_column, target_column])\n\n    # Ensure the target column is treated as categorical for hue\n    df[target_column] = df[target_column].astype(str)\n\n    # Calculate text lengths\n    df['text_length'] = df[text_column].apply(lambda x: len(str(x)))\n\n    # Plot the distribution of text lengths\n    plt.figure(figsize=(12, 6))\n    sns.histplot(\n        data=df,\n        x='text_length',\n        hue=target_column,\n        kde=True,\n        bins=30,\n        palette='viridis',\n        multiple='stack'\n    )\n    print(target_column)\n    plt.title('Distribution of Text Lengths by Target Class', fontsize=16)\n    plt.xlabel('Text Length', fontsize=14)\n    plt.ylabel('Frequency', fontsize=14)\n    plt.legend(df[target_column].unique(), fontsize=12)\n    plt.tight_layout()\n    plt.show()\n\n    # Print summary statistics for text lengths by target\n    print(\"Text Length Statistics by Target Class:\")\n    print(df.groupby(target_column)['text_length'].describe())\nplot_text_length_distribution(train_df, text_column='text', target_column='target')","metadata":{"id":"0cfluCrG0fhZ","outputId":"b150f694-1cf1-4298-8fea-0bc5f4869aeb"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot distribusi panjang text\ndef analyze_text_length(df, text_column='text'):\n    # Calculate text lengths\n    df['text_length'] = df[text_column].dropna().apply(len)\n\n    # Plot the distribution of text lengths\n    plt.figure(figsize=(10, 6))\n    sns.histplot(df['text_length'], kde=True, bins=30, color='blue')\n    plt.title('Distribution of Text Lengths', fontsize=16)\n    plt.xlabel('Text Length', fontsize=14)\n    plt.ylabel('Frequency', fontsize=14)\n    plt.show()\n\n    # Summary statistics for text lengths\n    print(df['text_length'].describe())\n# Analyze Text Length Distribution\nanalyze_text_length(test_df, text_column='text')","metadata":{"id":"jbvRhTwK3E6d","outputId":"36019190-e748-4681-fa3b-0296c5a07eee"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fungsi untuk menganalisis noise pada data\ndef analyze_noisy_data(df, text_column='text'):\n    # Patterns to detect noise\n    patterns = {\n        \"URLs\": r'https?://\\S+|www\\.\\S+',\n        \"HTML Tags\": r'<.*?>',\n        \"Emojis\": r'[^\\x00-\\x7F]',\n        \"Mentions (@)\": r'@\\w+',\n        \"Special Characters\": r'[^a-zA-Z0-9\\s]'\n    }\n\n    # Count occurrences of each type of noise\n    noise_counts = {}\n    for noise_type, pattern in patterns.items():\n        noise_counts[noise_type] = df[text_column].dropna().apply(lambda x: len(re.findall(pattern, x))).sum()\n\n    # Display noise statistics\n    print(\"Noise Statistics:\")\n    for noise_type, count in noise_counts.items():\n        print(f\"{noise_type}: {count}\")\n\n    # Visualize noise counts\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x=list(noise_counts.keys()), y=list(noise_counts.values()),palette='viridis')\n    plt.title('Presence of Noisy Data', fontsize=16)\n    plt.ylabel('Count', fontsize=14)\n    plt.xlabel('Noise Type', fontsize=14)\n    plt.xticks(rotation=45)\n    plt.show()","metadata":{"id":"OkPjt7RF09Ek"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Analyze Noisy Data\nanalyze_noisy_data(train_df, text_column='text')","metadata":{"id":"6lSQ9VpK3Bg-","outputId":"97b855e9-97c8-4885-a456-e5f77d5aa09a"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"bfNzUFOvOyni"}},{"cell_type":"code","source":"# Analyze Noisy Data\nanalyze_noisy_data(test_df, text_column='text')","metadata":{"id":"jq7scpfS3MxL","outputId":"93f61cba-617c-4167-904c-91a1646ac836"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"-Dk2NTrdOz5a"}},{"cell_type":"code","source":"# import pandas as pd\n# from collections import Counter\n# from sklearn.feature_extraction.text import CountVectorizer\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import nltk\n# from nltk.corpus import stopwords\n\n# # Download NLTK stopwords if not already installed\n# nltk.download('stopwords')","metadata":{"id":"3eeDb7z33R2U"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot kata yang umum\ndef analyze_common_words(df, text_column='text', n=10, custom_stopwords=None):\n    # Combine all text into one string\n    all_text = \" \".join(df[text_column].dropna().tolist())\n\n    # Tokenize words\n    words = all_text.split()\n\n    # Define stopwords: use the default STOPWORDS and add any custom stopwords if provided\n    stopwords = set(STOPWORDS)\n    if custom_stopwords:\n        stopwords.update(custom_stopwords)\n\n    # Remove stopwords from the word list\n    filtered_words = [word for word in words if word.lower() not in stopwords]\n\n    # Count word frequencies\n    word_counts = Counter(filtered_words)\n\n    # Get the most common words\n    common_words = word_counts.most_common(n)\n\n    # Print the most common words\n    print(\"Most Common Words (Excluding Stopwords):\")\n    for word, count in common_words:\n        print(f\"{word}: {count}\")\n\n    # Visualize\n    words, counts = zip(*common_words)\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x=list(counts), y=list(words), palette=\"viridis\")\n    plt.title(\"Most Common Words (Excluding Stopwords)\", fontsize=16)\n    plt.xlabel(\"Count\", fontsize=14)\n    plt.ylabel(\"Words\", fontsize=14)\n    plt.show()\n\n# Example usage\nanalyze_common_words(train_df, text_column='text', n=10, custom_stopwords={'-', '...','&amp;',\"|\",\"2\",\"??\",\"????\"})\n","metadata":{"id":"v2NqQTmU3RCT","outputId":"9343c9ac-ee18-43ea-c319-09c7f44f57f9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Wordcloud\ndef generate_wordcloud_from_dataframe(df, text_column, custom_stopwords=None):\n    # Combine all text data into one string\n    text = ' '.join(df[text_column].dropna().astype(str))\n\n    # Preprocess the text (remove special characters, URLs, etc.)\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n    text = text.lower()  # Convert to lowercase\n\n    # Define stopwords\n    stopwords = set(STOPWORDS)\n\n    # Add custom stopwords if provided\n    if custom_stopwords:\n        stopwords.update(custom_stopwords)\n\n    # Generate the word cloud\n    wordcloud = WordCloud(\n        width=800,\n        height=400,\n        background_color='white',\n        stopwords=stopwords,\n        colormap='viridis',\n        max_words=200\n    ).generate(text)\n\n    # Plot the word cloud\n    plt.figure(figsize=(12, 6))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.title(\"Word Cloud (Without Stopwords)\", fontsize=16)\n    plt.show()\n\n\n# Generate the word cloud\ngenerate_wordcloud_from_dataframe(train_df, text_column='text', custom_stopwords={'-', '...','&amp;',\"|\",\"2\",\"??\",\"????\",\"amp\",\"im\",\"u\",\"will\"})","metadata":{"id":"3aJtxEqyF5Rk","outputId":"244192a0-424d-4570-8028-26444e4c2227"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Plot N-grams\ndef analyze_ngrams(df, text_column='text', ngram_range=(2, 3), top_n=10):\n    # Vectorize to extract n-grams\n    vectorizer = CountVectorizer(ngram_range=ngram_range, stop_words='english')\n    ngrams = vectorizer.fit_transform(df[text_column].dropna())\n\n    # Count n-grams\n    ngram_counts = Counter(dict(zip(vectorizer.get_feature_names_out(), ngrams.sum(axis=0).A1)))\n\n    # Get the most common n-grams\n    common_ngrams = ngram_counts.most_common(top_n)\n\n    # Print the most common n-grams\n    print(f\"Most Common {ngram_range[0]}-grams:\")\n    for ngram, count in common_ngrams:\n        print(f\"{ngram}: {count}\")\n\n    # Visualize\n    ngrams, counts = zip(*common_ngrams)\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x=list(counts), y=list(ngrams), palette=\"magma\")\n    plt.title(f\"Most Common {ngram_range[0]}-grams\", fontsize=16)\n    plt.xlabel(\"Count\", fontsize=14)\n    plt.ylabel(f\"{ngram_range[0]}-grams\", fontsize=14)\n    plt.show()\nanalyze_ngrams(train_df, text_column='text', ngram_range=(2, 2), top_n=10)","metadata":{"id":"q3IUl9Q_Cbdi","outputId":"8e2ecaea-a57c-4291-f2a9-c96f27c47edd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Bar chart Trigrams\nanalyze_ngrams(train_df, text_column='text', ngram_range=(3, 3), top_n=10)","metadata":{"id":"336n7b4xCniH","outputId":"5f23d36e-4012-416f-e84a-5cd51a9d2120"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def identify_stopwords_abbreviations(df, text_column='text'):\n    # Get all text\n    all_text = \" \".join(df[text_column].dropna().tolist())\n\n    # Tokenize words\n    words = all_text.split()\n\n    # Load NLTK stopwords\n    stop_words = set(stopwords.words('english'))\n\n    # Identify stopwords\n    detected_stopwords = [word for word in words if word.lower() in stop_words]\n    print(f\"Detected Stopwords (Top 10): {Counter(detected_stopwords).most_common(10)}\")\n\n    # Identify potential abbreviations (all uppercase words)\n    abbreviations = [word for word in words if word.isupper() and len(word) > 1]\n    print(f\"Detected Abbreviations: {Counter(abbreviations).most_common(10)}\")\n\n    # (Optional) Identify domain-specific terms (requires external domain knowledge)\n    print(\"For domain-specific terms, define a dictionary or list of terms specific to your dataset's context.\")\n","metadata":{"id":"2U73L7WlCkIk"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Identify Stopwords, Abbreviations, and Domain-Specific Terms\nidentify_stopwords_abbreviations(train_df, text_column='text')","metadata":{"id":"26PPT9MXCsjY","outputId":"205ff016-ec22-468f-98af-26627f09dae3"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Preprocessing**","metadata":{"id":"aJwzTuJ-gvgA"}},{"cell_type":"code","source":"# Menginisialisasi WordNetLemmatizer\nlemmer = WordNetLemmatizer()\n\n# Fungsi untuk stemming\ndef stemming(tweet):\n    sb = SnowballStemmer('english')\n    s = ''\n    for word in tweet.split():\n        s += sb.stem(word) + ' '\n    return s.strip()\n\n# Fungsi untuk menghapus stopwords\nstopwords_set = set(stopwords.words('english'))  # pastikan stopwords diunduh\ndef remove_stopwords(tweet):\n    sentence = ' '.join(e.lower() for e in tweet.split() if e.lower() not in stopwords_set)\n    return sentence\n\n# Fungsi untuk membersihkan teks\ndef clean_text(text):\n    text = contractions.fix(text)\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n    text = re.sub(r'@\\w+', '', text)  # Remove mentions (@)\n    text = re.sub(r'\\brt\\b(?!\\w)', '', text)\n    text = re.sub(r\"[^a-zA-Z\\d\\s]\", \"\", text)  # Remove everything except letters, digits, and spaces\n    text = re.sub(r\"[0-9]\", \"\", text)  # Remove numbers\n    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove emojis\n    text = text.lower()  # Convert to lowercase\n    return text.strip()\n\n# Fungsi lemmatization menggunakan WordNetLemmatizer\ndef preprocess_wordnet(text):\n    # Tokenisasi kalimat menjadi kata-kata\n    words = word_tokenize(text)\n    # Lemmatization\n    lemmatized_text = ' '.join([lemmer.lemmatize(word) for word in words])\n    return lemmatized_text\n\n# Preprocessing Lengkap\ndef preprocessing(train_df, test_df):\n    # 2. Clean text\n    train_df['clean_text'] = train_df['text'].apply(clean_text)\n    test_df['clean_text'] = test_df['text'].apply(clean_text)\n\n    # 3. Lemmatize using WordNet\n    train_df['clean_text'] = train_df['clean_text'].apply(preprocess_wordnet)\n    test_df['clean_text'] = test_df['clean_text'].apply(preprocess_wordnet)\n\n    # 4. Remove stopwords\n    train_df['clean_text'] = train_df['clean_text'].apply(remove_stopwords)\n    test_df['clean_text'] = test_df['clean_text'].apply(remove_stopwords)\n\n    # 5. Stemming\n    train_df['clean_text'] = train_df['clean_text'].apply(stemming)\n    test_df['clean_text'] = test_df['clean_text'].apply(stemming)\n\n    return train_df, test_df","metadata":{"id":"dOKcFhpzRZm0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocessing Data\ntrain_df, test_df = preprocessing(train_df, test_df)\n\n# TF-IDF Vectorization\ntfidf = TfidfVectorizer(\n    max_features=10000,  # Tambahkan jumlah fitur\n    min_df=1,  # Pertimbangkan kata yang jarang muncul\n    ngram_range=(1, 2),  # Gunakan bigram\n    sublinear_tf=True  # Scaling TF-IDF\n)\nX_train = tfidf.fit_transform(train_df['clean_text'])\nX_test = tfidf.transform(test_df['clean_text'])\n\n# Prepare Target Variable\ny_train = train_df['target']\n\n# Split Data (Train-Validation Split)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=SEED)","metadata":{"id":"LmkJk3Elmxey"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', None)\n\n# Melihat hasil preprocessing\ntrain_df[['text', 'target', 'clean_text']].head(20)","metadata":{"collapsed":true,"outputId":"b07d6947-b06c-46c6-f02a-f26880bde6dd","id":"CQHR7AdYRZm3","jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Modelling**","metadata":{"id":"67ocoszDgy8Q"}},{"cell_type":"code","source":"# Logistic Regression Model\nlogreg_model = LogisticRegression(random_state=SEED)\nlogreg_model.fit(X_train, y_train)\nlogreg_y_val_pred = logreg_model.predict(X_val)\nprint(\"Logistic Regression Validation Accuracy:\", accuracy_score(y_val, logreg_y_val_pred))\nprint(\"\\nClassification Report for Logistic Regression:\\n\", classification_report(y_val, logreg_y_val_pred))\n\n# Random Forest Model\nrf_model = RandomForestClassifier(random_state=SEED)\nrf_model.fit(X_train, y_train)\nrf_y_val_pred = rf_model.predict(X_val)\nprint(\"Random Forest Validation Accuracy:\", accuracy_score(y_val, rf_y_val_pred))\nprint(\"\\nClassification Report for Random Forest:\\n\", classification_report(y_val, rf_y_val_pred))\n\n# Naive Bayes Model\nnb_model = MultinomialNB()\nnb_model.fit(X_train, y_train)\nnb_y_val_pred = nb_model.predict(X_val)\nprint(\"Naive Bayes Validation Accuracy:\", accuracy_score(y_val, nb_y_val_pred))\nprint(\"\\nClassification Report for Naive Bayes:\\n\", classification_report(y_val, nb_y_val_pred))\n\n# SVM Model\nsvm_model = SVC(kernel='linear', random_state=SEED)\nsvm_model.fit(X_train, y_train)\nsvm_y_val_pred = svm_model.predict(X_val)\nprint(\"SVM Validation Accuracy:\", accuracy_score(y_val, svm_y_val_pred))\nprint(\"\\nClassification Report for SVM:\\n\", classification_report(y_val, svm_y_val_pred))\n\n# Gradient Boosting Model\ngb_model = GradientBoostingClassifier(random_state=SEED)\ngb_model.fit(X_train, y_train)\ngb_y_val_pred = gb_model.predict(X_val)\nprint(\"Gradient Boosting Validation Accuracy:\", accuracy_score(y_val, gb_y_val_pred))\nprint(\"\\nClassification Report for Gradient Boosting:\\n\", classification_report(y_val, gb_y_val_pred))\n\n# XGBoost Model\nxgb_model = XGBClassifier(random_state=SEED, use_label_encoder=False, eval_metric='logloss')\nxgb_model.fit(X_train, y_train)\nxgb_y_val_pred = xgb_model.predict(X_val)\nprint(\"XGBoost Validation Accuracy:\", accuracy_score(y_val, xgb_y_val_pred))\nprint(\"\\nClassification Report for XGBoost:\\n\", classification_report(y_val, xgb_y_val_pred))\n\n# LightGBM Model\nlgbm_model = LGBMClassifier(random_state=SEED)\nlgbm_model.fit(X_train, y_train)\nlgbm_y_val_pred = lgbm_model.predict(X_val)\nprint(\"LightGBM Validation Accuracy:\", accuracy_score(y_val, lgbm_y_val_pred))\nprint(\"\\nClassification Report for LightGBM:\\n\", classification_report(y_val, lgbm_y_val_pred))\n\n# Voting Classifier (Ensemble of Models)\nvoting_model = VotingClassifier(estimators=[\n    ('logreg', logreg_model),\n    ('rf', rf_model),\n    #('xgb', xgb_model),\n    ('svm', svm_model)\n], voting='hard')\n\nvoting_model.fit(X_train, y_train)\nvoting_y_val_pred = voting_model.predict(X_val)\nprint(\"Voting Classifier Validation Accuracy:\", accuracy_score(y_val, voting_y_val_pred))\nprint(\"\\nClassification Report for Voting Classifier:\\n\", classification_report(y_val, voting_y_val_pred))","metadata":{"outputId":"8b45efc7-a202-4cfe-d1c0-c17428b4ce2d","id":"IYYz0mAiRrEC"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Interpretasi :\n\n1. Logistic Regression:  \n  Accuracy: 81.17%\n  Precision dan Recall untuk kelas Disaster (1) lebih rendah dibandingkan Not Disaster (0), tapi masih cukup baik (precision 85%, recall 71%).\n  F1-score: Model seimbang untuk Not Disaster (84%) dan Disaster (77%).\n\n2. Random Forest:  \n  Accuracy: 79.70%  \n  Precision dan Recall untuk Not Disaster (0) cukup baik, namun lebih rendah untuk Disaster (1) (precision 84%, recall 69%).  \n  Model cenderung lebih kuat di kelas Not Disaster, dengan F1-score 83% dan 75% untuk kelas 0 dan 1.\n  \n3. Naive Bayes:  \n  Accuracy: 80.64%  \n  Precision dan recall untuk Not Disaster (0) cukup baik (precision 77%, recall 91%), namun agak kurang untuk Disaster (1) (precision 87%, recall 68%).  \n  F1-score untuk Not Disaster lebih tinggi (84%) dibandingkan Disaster (76%).  \n\n4. SVM:  \n  Accuracy: 80.91%  \n  Precision dan recall hampir seimbang antara kelas Not Disaster (precision 80%, recall 88%) dan Disaster (precision 83%, recall 73%).  \n  F1-score untuk Not Disaster lebih baik (83%) daripada untuk Disaster (78%).\n\n5. Gradient Boosting:  \n  Accuracy: 74.63%  \n  Model menunjukkan precision yang lebih tinggi untuk Disaster (1) (89%) tetapi recall yang sangat rendah (51%).  \n  F1-score untuk kelas Disaster rendah (64%), sementara Not Disaster lebih baik (80%).\n\n6. XGBoost:  \n  Accuracy: 79.17%  \n  Precision untuk Disaster 84% dan recall 67%, sedikit lebih baik daripada\n  Random Forest dan Naive Bayes dalam mendeteksi kelas Disaster.  \n  F1-score seimbang di 82% untuk Not Disaster dan 75% untuk Disaster.\n\n7. LightGBM:  \n  Accuracy: 79.71%  \n  Model ini mirip dengan Random Forest, dengan precision dan recall lebih baik untuk Not Disaster dan sedikit lebih rendah untuk Disaster.  \n  F1-score untuk Not Disaster (83%) lebih baik daripada untuk Disaster (76%).\n\n8. Voting Classifier:  \n  Accuracy: 80.91%  \n  Precision dan Recall seimbang untuk Not Disaster (precision 79%, recall 89%) dan Disaster (precision 84%, recall 71%).  \n  F1-score 84% untuk Not Disaster dan 77% untuk Disaster, menunjukkan kinerja yang cukup baik dan seimbang di kedua kelas.","metadata":{"id":"MKNPjgcxnLu4"}},{"cell_type":"markdown","source":"## **Model Evaluation: F1 Score**","metadata":{"id":"IH-HkiTIgy6N"}},{"cell_type":"code","source":"# F1-score untuk setiap model\nmodels = ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'SVM', 'Gradient Boosting', 'XGBoost', 'LightGBM', 'Voting Classifier']\n\nf1_scores = [\n    classification_report(y_val, logreg_y_val_pred, output_dict=True)['weighted avg']['f1-score'],\n    classification_report(y_val, rf_y_val_pred, output_dict=True)['weighted avg']['f1-score'],\n    classification_report(y_val, nb_y_val_pred, output_dict=True)['weighted avg']['f1-score'],\n    classification_report(y_val, svm_y_val_pred, output_dict=True)['weighted avg']['f1-score'],\n    classification_report(y_val, gb_y_val_pred, output_dict=True)['weighted avg']['f1-score'],\n    classification_report(y_val, xgb_y_val_pred, output_dict=True)['weighted avg']['f1-score'],\n    classification_report(y_val, lgbm_y_val_pred, output_dict=True)['weighted avg']['f1-score'],\n    classification_report(y_val, voting_y_val_pred, output_dict=True)['weighted avg']['f1-score']\n]\n\n# Gabungkan nama model dan F1-score\nmodel_f1_scores = sorted(zip(models, f1_scores), key=lambda x: x[1])\n\n# Sort\nsorted_models, sorted_f1_scores = zip(*model_f1_scores)\n\n# Bar Chart\nplt.figure(figsize=(12,6))  # Memperlebar ukuran gambar\nbars = plt.barh(sorted_models, sorted_f1_scores, color='skyblue')\n\n# Menambahkan angka di ujung setiap bar\nfor bar in bars:\n    plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2,\n             f'{bar.get_width():.4f}', va='center', ha='left', color='black')\n\nplt.xlabel('F1 Score')\nplt.title('F1 Score Comparison')\n\n# Menambahkan margin untuk menghindari angka terpotong\nplt.tight_layout()\nplt.show()","metadata":{"id":"pbxuDlM1q4yw","outputId":"2d5ac12b-64fc-48e0-993e-a3ee8b38c085"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"F1 Scores for All Models:\")\nfor model, f1 in zip(sorted_models, sorted_f1_scores):\n    print(f\"{model}: {f1:.5f}\")","metadata":{"id":"U1dwXkStb74C","outputId":"0111d285-6b0a-40c1-8b82-7423e149a817"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Interpretasi :  \nModel logistic regression, SVM, dan Voting classifier memberikan hasil yang cukup baik untuk f1 score. Untuk proses selanjutnya, kami memutuskan untuk menggunakan Model SVM.","metadata":{"id":"sXxhmAK2oKCi"}},{"cell_type":"markdown","source":"## **Hyperparameter Tuning**","metadata":{"id":"rKsf9U6Mg-WA"}},{"cell_type":"markdown","source":"### SVM","metadata":{"id":"QCwzWgBNuxsI"}},{"cell_type":"code","source":"# Parameter grid\nparam_grid_svm = {\n    'C': [0.1, 1, 10],  # Regularisasi\n    'kernel': ['linear', 'rbf'],\n    'gamma': ['scale', 'auto']\n}\n\n# Inisialisasi GridSearchCV\ngrid_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, n_jobs=-1)\n\n# Fit model\ngrid_svm.fit(X_train, y_train)\n\n# Tampilkan hasil\nprint(\"Best parameters found: \", grid_svm.best_params_)\nprint(\"Best cross-validation score: \", grid_svm.best_score_)","metadata":{"outputId":"40e27f16-4a00-4654-89b2-f0add52ecef8","id":"XzK1zbjBRrEE"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Berdasarkan hasil hyperparameter tuning, didapatkan parameter terbaiknya adalah :  \n{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}","metadata":{"id":"S5ht_N4yotG2"}},{"cell_type":"code","source":"best_params = grid_svm.best_params_\nsvm_best_model = SVC(C=best_params['C'], gamma=best_params['gamma'], kernel=best_params['kernel'], random_state=825)\n\n# Train model\nsvm_best_model.fit(X_train, y_train)\n\n# Prediksi menggunakan data validasi\nsvm_y_val_pred = svm_best_model.predict(X_val)\n\n# Evaluasi model\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Akurasi\nprint(\"SVM Validation Accuracy:\", accuracy_score(y_val, svm_y_val_pred))\n\n# Classification Report\nprint(\"\\nClassification Report for SVM:\\n\", classification_report(y_val, svm_y_val_pred))","metadata":{"outputId":"f3b19a09-886f-4110-de99-30096a40fe9b","id":"F9w9hVeVRrEF"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Voting model","metadata":{"id":"9NkXU5mhu00l"}},{"cell_type":"code","source":"# Define parameter grids for each individual model\nlogreg_param_grid = {\n    'C': [0.1, 1, 10],  # Regularization strength for Logistic Regression\n    'solver': ['liblinear', 'saga']\n}\n\nrf_param_grid = {\n    'n_estimators': [50, 100, 200],  # Number of trees in Random Forest\n    'max_depth': [10, 20, None]       # Maximum depth of the trees\n}\n\nsvm_param_grid = {\n    'C': [0.1, 1, 10],  # Regularization parameter for SVM\n    'kernel': ['linear', 'rbf']\n}\n\n# Perform grid search for each model\nlogreg_grid_search = GridSearchCV(LogisticRegression(random_state=42), logreg_param_grid, cv=5)\nrf_grid_search = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5)\nsvm_grid_search = GridSearchCV(SVC(random_state=42), svm_param_grid, cv=5)\n\n# Fit the grid search models\nlogreg_grid_search.fit(X_train, y_train)\nrf_grid_search.fit(X_train, y_train)\nsvm_grid_search.fit(X_train, y_train)\n\n# Print best parameters for each model\nprint(\"Best parameters for Logistic Regression:\", logreg_grid_search.best_params_)\nprint(\"Best parameters for Random Forest:\", rf_grid_search.best_params_)\nprint(\"Best parameters for SVM:\", svm_grid_search.best_params_)\n\n# Use the best models from grid search to create the VotingClassifier\nvoting_best_model = VotingClassifier(estimators=[\n    ('logreg', logreg_grid_search.best_estimator_),\n    ('rf', rf_grid_search.best_estimator_),\n    ('svm', svm_grid_search.best_estimator_)\n], voting='hard')\n\n# Fit and evaluate the Voting Classifier\nvoting_best_model.fit(X_train, y_train)\nvoting_y_val_pred = voting_best_model.predict(X_val)\nprint(\"Voting Classifier Validation Accuracy:\", accuracy_score(y_val, voting_y_val_pred))\nprint(\"\\nClassification Report for Voting Classifier:\\n\", classification_report(y_val, voting_y_val_pred))","metadata":{"id":"oAOX76pFu57q","outputId":"79a152fc-de3c-42f6-b3e7-aac05473f525"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Confussion Matrix","metadata":{"id":"dcPAtR3E5SKv"}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\n# Confusion matrix for SVM model\nsvm_conf_matrix = confusion_matrix(y_val, svm_y_val_pred)\nprint(\"Confusion Matrix for SVM:\\n\", svm_conf_matrix)\n\n# Display confusion matrix for SVM\nsvm_disp = ConfusionMatrixDisplay(confusion_matrix=svm_conf_matrix, display_labels=svm_best_model.classes_)\nsvm_disp.plot()\nplt.title(\"Confusion Matrix for SVM\")\nplt.show()\n\n# Confusion matrix for Voting Classifier\nvoting_conf_matrix = confusion_matrix(y_val, voting_y_val_pred)\nprint(\"Confusion Matrix for Voting Classifier:\\n\", voting_conf_matrix)\n\n# Display confusion matrix for Voting Classifier\nvoting_disp = ConfusionMatrixDisplay(confusion_matrix=voting_conf_matrix, display_labels=voting_best_model.classes_)\nvoting_disp.plot()\nplt.title(\"Confusion Matrix for Voting Classifier\")\nplt.show()","metadata":{"id":"V4UpyDuY5Tzw","outputId":"c403e1ad-56a8-46b7-add3-8ea796e8eb79"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Submission**","metadata":{"id":"-6uvSWvagy3R"}},{"cell_type":"code","source":"# Predict on Test Data\nbest_pred = svm_best_model.predict(X_test)\n# best_pred = voting_best_model.predict(X_test)\n\n# Save Predictions\nsubmission = pd.DataFrame({\n    'id': ss_df['id'],\n    'target': best_pred\n})\nsubmission.to_csv('submission_final.csv', index=False)\nprint(\"Submission saved successfully.\")","metadata":{"id":"hxwMoqYThOfZ","outputId":"83d32526-d924-4303-a7c8-cb63fea0338e"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Pre-Trained Model**","metadata":{"id":"5rd8NTbes-Mb"}},{"cell_type":"code","source":"from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\nimport torch\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport os\n\n# Disable Weights and Biases logging\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# Load Dataset\n# Pastikan train_df sudah memiliki kolom 'text' dan 'target'\ntrain_texts = train_df['text'].tolist()\ntrain_labels = train_df['target'].tolist()\n\n# Split Data (Train-Test Split)\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    train_texts, train_labels, test_size=0.2, random_state=42\n)\n\n# Load Pre-trained Tokenizer\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n\n# Tokenize Data\ndef tokenize_function(texts):\n    return tokenizer(texts, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n\ndef prepare_encodings(texts, labels):\n    encodings = tokenizer(texts, padding='max_length', truncation=True, max_length=128)\n    encodings['labels'] = labels\n    return encodings\n\ntrain_encodings = prepare_encodings(train_texts, train_labels)\nval_encodings = prepare_encodings(val_texts, val_labels)\n\n# Convert to Torch Dataset\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __len__(self):\n        return len(self.encodings['labels'])\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        return item\n\ntrain_dataset = CustomDataset(train_encodings)\nval_dataset = CustomDataset(val_encodings)\n\n# Load Pre-trained Model\nmodel = RobertaForSequenceClassification.from_pretrained(\n    'roberta-base', num_labels=2\n)\n\n# Define Training Arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',           # Directory to save results\n    evaluation_strategy='epoch',     # Evaluate every epoch\n    save_strategy='epoch',           # Save every epoch\n    learning_rate=2e-5,              # Learning rate\n    per_device_train_batch_size=16,  # Batch size\n    per_device_eval_batch_size=16,   # Evaluation batch size\n    num_train_epochs=3,              # Number of epochs\n    weight_decay=0.01,               # Weight decay\n    logging_dir='./logs',            # Directory for logs\n    logging_steps=10,                # Log every 10 steps\n    load_best_model_at_end=True,     # Load the best model\n)\n\n# Define Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset\n)\n\n# Train the Model\ntrainer.train()\n\n# Save the Model\ntrainer.save_model('./roberta-finetuned')\ntokenizer.save_pretrained('./roberta-finetuned')\n\n# Evaluate the Model\nresults = trainer.evaluate()\nprint(\"Evaluation Results:\", results)","metadata":{"id":"QyXTnYHLpqwU","outputId":"84e047e2-c067-4394-aa3c-80d405e6e880"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict on Test Data\ntest_texts = test_df['text'].tolist()\ntest_encodings = tokenizer(test_texts, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n\n# Convert test data to Dataset (without labels)\nclass TestDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __len__(self):\n        return len(self.encodings['input_ids'])\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        return item\n\ntest_dataset = TestDataset(test_encodings)\n\n# Generate predictions\npredictions = trainer.predict(test_dataset)\npredicted_labels = torch.argmax(torch.tensor(predictions.predictions), axis=1).tolist()\n\n# Save predictions\nsubmission = pd.DataFrame({\n    'id': test_df['id'],\n    'target': predicted_labels\n})\nsubmission.to_csv('submission_roberta.csv', index=False)\nprint(\"Submission saved successfully.\")","metadata":{"id":"mP-oM4xMpwKv","outputId":"7047c0e8-0b8d-41b5-8b9d-3bcce95e8e3b"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Modelling Pretrained: Fine-Tuning Roberta**\n\nTujuan: Menggunakan model bahasa berbasis transformer, Roberta, yang telah dilatih sebelumnya untuk meningkatkan akurasi klasifikasi sentimen tweet.\n\n**Tahapan Proses**\n1. Tokenisasi:\n\n  Data teks diubah menjadi token menggunakan tokenizer bawaan Roberta.\n  Panjang maksimum tokenisasi diatur ke 128 untuk mempertahankan konteks tetapi tetap efisien.\n\n2. Fine-Tuning:\n\n  Model Roberta-base dilatih ulang pada dataset dengan dua label (binary classification). Parameter utama:\n  - Learning rate: 2e-5\n  - Batch size: 16\n  - Jumlah epoch: 3\n  - Weight decay: 0.01\n  - Model dievaluasi pada set validasi setelah setiap epoch.\n\n3. Hasil Pelatihan:\n\n  Loss training cenderung stabil pada epoch pertama, tetapi menunjukkan peningkatan pada epoch ke-3.\n  Validation Loss meningkat, yang dapat mengindikasikan overfitting pada akhir pelatihan.\n\n4. Evaluasi Model:\n\n  Model dievaluasi menggunakan metrik bawaan Hugging Face Trainer:\n  - Validation loss: 0.396559 (epoch 1) hingga 0.476117 (epoch 3).\n  - Runtime Evaluasi: 9.6 detik dengan rata-rata 158 sampel per detik.\n  \n  Hasil menunjukkan bahwa model berhasil mengklasifikasikan data dengan akurasi baik namun memerlukan pengendalian overfitting.","metadata":{"id":"i17C2ieEyw7f"}},{"cell_type":"code","source":"","metadata":{"id":"xd-BmiWezT5b"},"outputs":[],"execution_count":null}]}
